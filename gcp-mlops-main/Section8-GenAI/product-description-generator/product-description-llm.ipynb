{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08fa730e-5c3c-4e7a-9b7c-b8e3a44cac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040729eb-0d7b-4336-8d3b-623beac503d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f1284d-c141-4efb-88f3-c2c81058960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://github-repo/product_img/\n",
      "gs://github-repo/product_img/fashion1.jpeg\n",
      "gs://github-repo/product_img/fashion2.jpeg\n",
      "gs://github-repo/product_img/fashion3.jpeg\n",
      "gs://github-repo/product_img/fashion4.jpeg\n",
      "gs://github-repo/product_img/fashion5.jpeg\n",
      "gs://github-repo/product_img/fashion6.jpeg\n",
      "gs://github-repo/product_img/fashion7.jpeg\n",
      "gs://github-repo/product_img/fashion8.jpeg\n"
     ]
    }
   ],
   "source": [
    "GCS_BUCKET = \"github-repo\"\n",
    "!gsutil ls gs://$GCS_BUCKET/product_img/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0090e664-b6cc-4a18-9bb7-40a99ae16eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-transformers-serve\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3dbeeb0-dd1e-4e73-9c66-9f09f0de013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_name(prefix):\n",
    "    user = os.environ.get(\"USER\")\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    job_name = f\"{prefix}-{user}-{now}\"\n",
    "    return job_name\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "def image_to_base64(image, format=\"JPEG\"):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def deploy_model(model_id, task):\n",
    "    model_name = \"blip-image-captioning\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": model_id,\n",
    "        \"TASK\": task,\n",
    "    }\n",
    "    # If the model_id is a GCS path, use artifact_uri to pass it to serving docker.\n",
    "    artifact_uri = model_id if model_id.startswith(\"gs://\") else None\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/predictions/transformers_serving\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "        artifact_uri=artifact_uri,\n",
    "    )\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=\"n1-standard-8\",\n",
    "        accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "        accelerator_count=1,\n",
    "        deploy_request_timeout=1800,\n",
    "    )\n",
    "    return model, endpoint\n",
    "\n",
    "\n",
    "def read_jpeg_image_from_gcs(bucket_name, image_name):\n",
    "    \"\"\"Reads a JPEG image from a Google Cloud Storage (GCS) bucket.\n",
    "\n",
    "    Args:\n",
    "    bucket_name: The name of the GCS bucket that contains the image file.\n",
    "    image_name: The name of the image file in the GCS bucket.\n",
    "\n",
    "    Returns:\n",
    "    The image file as a PIL Image object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Import the Google Cloud Storage client library.\n",
    "\n",
    "    # Create a storage client.\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Get the bucket object.\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Get the blob object.\n",
    "    blob = bucket.blob(image_name)\n",
    "\n",
    "    # Read the blob to a bytestring.\n",
    "    image_data = blob.download_as_bytes()\n",
    "\n",
    "    # Decode the bytestring to a PIL Image object.\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "    # Return the PIL Image object.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f1db8-fc28-483b-a84a-e1d92c3d8f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/1090925531874/locations/us-central1/endpoints/3755019125831761920/operations/2906612520498233344\n",
      "Endpoint created. Resource name: projects/1090925531874/locations/us-central1/endpoints/3755019125831761920\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/1090925531874/locations/us-central1/endpoints/3755019125831761920')\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/1090925531874/locations/us-central1/models/7469648791528800256/operations/8698241641296691200\n",
      "Model created. Resource name: projects/1090925531874/locations/us-central1/models/7469648791528800256@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1090925531874/locations/us-central1/models/7469648791528800256@1')\n",
      "Deploying model to Endpoint : projects/1090925531874/locations/us-central1/endpoints/3755019125831761920\n",
      "Deploy Endpoint model backing LRO: projects/1090925531874/locations/us-central1/endpoints/3755019125831761920/operations/2141000583845249024\n"
     ]
    }
   ],
   "source": [
    "model, endpoint = deploy_model(\n",
    "    model_id=\"Salesforce/blip-image-captioning-base\", task=\"image-to-text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c581c58-ada6-4465-a15e-e54a728cde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_product_description(model, image_caption, temperature=0):\n",
    "    \"\"\"Ideation example with a Large Language Model\"\"\"\n",
    "    prompt_prefix = \"Imagine you are a digital marketer working for a retail organization. \\\n",
    "                    You are an expert in building detailed and catchy descriptions fro the retail fashion products on your website.\\\n",
    "                    Generate a product description using the following short caption that describes the apparel\"\n",
    "    prompt = prompt_prefix + image_caption\n",
    "    response = model.predict(\n",
    "        prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=256,\n",
    "        top_k=40,\n",
    "        top_p=0.8,\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e96701-9a19-49e8-8477-13a6c7315c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in range(1, 9):\n",
    "    image_data = read_jpeg_image_from_gcs(\n",
    "        GCS_BUCKET, \"product_img/fashion\" + str(i) + \".jpeg\"\n",
    "    )\n",
    "    # Display the image\n",
    "    plt.imshow(image_data)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    instances = [\n",
    "        {\"image\": image_to_base64(image_data)},\n",
    "    ]\n",
    "    preds = endpoint.predict(instances=instances).predictions\n",
    "    print(preds)\n",
    "    product_description = generate_product_description(\n",
    "        model=generation_model, image_caption=preds[0]\n",
    "    )\n",
    "    print(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923481e-6098-4412-acbf-2d47ca408818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf5416-ea53-4c45-a085-c9befbd2eaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b32f81-fe43-41f7-9ea4-0fdfdb8c6822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e860ab1-82a5-4141-8ace-ef9d243000bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e7a5d-1595-41a0-bb5c-3e2e23af3a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf8fed-5043-42e6-91c3-1f8757a00037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
